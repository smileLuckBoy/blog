---
title: '深入浅出:HashMap(一)'
toc: true
date: 2016-09-06 21:41:12
tags: [collection,深入浅出]
categories: JAVA
---


HashMap这种数据结构对我们来说一点都不陌生，简单的讲，就是Key-Value对，常用的API诸如put，get等，感觉so easy啊，其实这只是最简单的对HashMap的认知，这段时间通过源码研究了下HashMap的原理，瞬间感觉懵逼了...

下面我们通过分析JDK来分析下HashMap，本次研究基于JDK版本<font color='red'>**1.8**</font>，JDK1.8对HashMap做了很多的改进(面目全非)，感觉比之前版本的高深了许多(好吧，我承认自己很菜)...


<!-- more -->

### 数据结构

HashMap的数据存储结构如下图所示：
![](http://od6ojrbik.bkt.clouddn.com/images/blog/2016-09-06-1.png)

注：这张图片是从其它地方copy过来的，这里还是要说明下的~
我们可以看到HashMap中包含的数据结构有如下几种:

#### 数组

```java
/**
 * The table, initialized on first use, and resized as
 * necessary. When allocated, length is always a power of two.
 * (We also tolerate length zero in some operations to allow
 * bootstrapping mechanics that are currently not needed.)
 */
transient Node<K,V>[] table;
```
HashMap的键值对都是存放在Node&lt;K,V&gt;[] table这么一个table中的，table中的元素既可以是单向链表Node，也可以是红黑树TreeNode（很多地方喜欢把他们称为Bucket），可能会有童鞋疑惑了，数组的类型明明是Node类型的，怎么可以存放ThreeNode类型的元素呢？

继承？bingo！的确是这样的，ThreeNode&lt;K,V&gt;继承自LinkedHashMap.Entry&lt;K,V&gt;，而LinkedHashMap.Entry&lt;K,V&gt;有是继承自HashMap.Node&lt;K,V&gt;



#### 链表
```java
/**
 * Basic hash bin node, used for most entries.  (See below for
 * TreeNode subclass, and in LinkedHashMap for its Entry subclass.)
 */
static class Node<K,V> implements Map.Entry<K,V> {
    // 用来定位node在哈希表中的位置
    final int hash;
    final K key;
    V value;
    // 下一个node，表明Node结构是一个单向链表
    Node<K,V> next;
    Node(int hash, K key, V value, Node<K,V> next) { ... }
    public final K getKey()        { ... }
    public final V getValue()      { ... }
    public final String toString() { ... }
    public final int hashCode() { ... }
    public final V setValue(V newValue) { ... }
    public final boolean equals(Object o) { ... }
}
```

很简单的一个链表的实现~



#### 红黑树
这里暂时不做讨论


---


### 基础知识


#### 类的属性


```java
/**
  * HashMap的初始容量，默认值为16，必须为2的幂次方
  */
 static final int DEFAULT_INITIAL_CAPACITY = 1 << 4; // aka 16

 /**
  * HashMap的最大容量，为2的30次方，必须为2的幂次方
  */
 static final int MAXIMUM_CAPACITY = 1 << 30;

 /**
  * HashMap的加载因子，默认值为0.75
  */
 static final float DEFAULT_LOAD_FACTOR = 0.75f;

 /**
  * 当链表中元素的个数超过该值后，链表会转换为红黑树
  */
 static final int TREEIFY_THRESHOLD = 8;

 /**
  * 在resize时，如果红黑树的子节点到达该值后，红黑树转换为链表
  */
 static final int UNTREEIFY_THRESHOLD = 6;

 /**
  * 当链表中元素超过8个后，如果哈希表的size小于该值后会进行resize，如果大于该值后，才进行转换
  * MIN_TREEIFY_CAPACITY的值至少是TREEIFY_THRESHOLD的4倍
  */
  static final int MIN_TREEIFY_CAPACITY = 64;

/**
  * HashMap中Key-Value对的数量
  */
 transient int size;

 /**
  * HashMap结构发生改变的次数，比如put、clear等操作时
  * 该值为HashMap fast-fail提供了依据
  */
 transient int modCount;

 /**
  * HashMap扩容的阈值 (threshol = capacity * load factor).
  * 当哈希表为空时，threshol为哈希表初始容量(此处和低版本描述不同)
  */
 int threshold;

 /**
  * 加载因子,有没有童鞋想过为什么需要加载因子以及为什么需要阈值？
  * 答案之后揭晓
  */
 final float loadFactor;

```


#### 构造方法

HashMap有三个构造方法，这三个构造方法同样比较之前版本改动较大

```java
/**
 * Constructs an empty <tt>HashMap</tt> with the default initial capacity
 * (16) and the default load factor (0.75).
 */
public HashMap() {
    this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted
}


/**
 * Constructs an empty <tt>HashMap</tt> with the specified initial
 * capacity and the default load factor (0.75).
 *
 * @param  initialCapacity the initial capacity.
 * @throws IllegalArgumentException if the initial capacity is negative.
 */
public HashMap(int initialCapacity) {
    this(initialCapacity, DEFAULT_LOAD_FACTOR);
}


/**
 * Constructs an empty <tt>HashMap</tt> with the specified initial
 * capacity and load factor.
 *
 * @param  initialCapacity the initial capacity
 * @param  loadFactor      the load factor
 * @throws IllegalArgumentException if the initial capacity is negative
 *         or the load factor is nonpositive
 */
public HashMap(int initialCapacity, float loadFactor) {
    if (initialCapacity < 0)
        throw new IllegalArgumentException("Illegal initial capacity: " +
                                               initialCapacity);
    if (initialCapacity > MAXIMUM_CAPACITY)
        initialCapacity = MAXIMUM_CAPACITY;
    if (loadFactor <= 0 || Float.isNaN(loadFactor))
        throw new IllegalArgumentException("Illegal load factor: " +
                                               loadFactor);
    this.loadFactor = loadFactor;
    // threshold为HashMap的初始容量
    this.threshold = tableSizeFor(initialCapacity);
}


```
**注意**：到此处HashMap中的Node[]还并没有分配空间,Node[]什么时候分配空间呢？我们继续向下看~


我们来看下函数tableSizeFor()

```java
/**
  * Returns a power of two size for the given target capacity.
  */
static final int tableSizeFor(int cap) {
    int n = cap - 1;
    n |= n >>> 1;
    n |= n >>> 2;
    n |= n >>> 4;
    n |= n >>> 8;
    n |= n >>> 16;
    return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;
}

```
基本的位运算操作，巧妙的是，通过函数tableSizeFor，可以有效的将我们输入的数值转化最接近的2的幂次方，比如说，入参cap=5，那么输出就是8；入参是12，输出就是16，HashMap中涉及的位操作运算很多，看不懂的童鞋这边需要恶补一下了哈~
下面我们分析下这段代码为什么可以实现这样的功能：
```
十进制：5；二进制：101
转换： ①101 - > 111  ②111 + 1 = 1000 = 8
无非就是要将所有的二进制位全部变化成1，最后再加个1就可以了，没啥好解释的~
```

比对一下之前版本的代码，还是之前的比较好理解点哎，虽然效率可能会不及上述代码~
```java
int capacity = 1;
while (capacity < initialCapacity)
    capacity <<= 1;
```


#### 哈希算法
如何将Key映射成一个int类型的值？jdk为我们提供了如下算法：
```java
/**
 * Computes key.hashCode() and spreads (XORs) higher bits of hash
 * to lower.  Because the table uses power-of-two masking, sets of
 * hashes that vary only in bits above the current mask will
 * always collide. (Among known examples are sets of Float keys
 * holding consecutive whole numbers in small tables.)  So we
 * apply a transform that spreads the impact of higher bits
 * downward. There is a tradeoff between speed, utility, and
 * quality of bit-spreading. Because many common sets of hashes
 * are already reasonably distributed (so don't benefit from
 * spreading), and because we use trees to handle large sets of
 * collisions in bins, we just XOR some shifted bits in the
 * cheapest possible way to reduce systematic lossage, as well as
 * to incorporate impact of the highest bits that would otherwise
 * never be used in index calculations because of table bounds.
 */
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}

public native int hashCode();
```
这边需要注意的有两点：
* key的哈希值是key的hashCode高16位异或低16位组成的，这样做的目的就是为了更加匀称的得到一个哈希值，使得在哈希表容量较小的时候，高位bit也可以参与到计算哈希值的过程中
* 如果采用自定义的obj来做key，那么自定义的obj需要<font color="red">**同时实现hashCode方法和equals方法**</font>，后续比较key是否相同的时候，会频繁的用到这两个方法


#### 计算数组下标

通过`(cap - 1) & hash`获取数组下标：
这个方法看起来很怪异，其实就是很怪异，我们来仔细研究下：cap是数组的长度，而且是2的幂次方，hash是key的哈希值，`(cap-1) & hash`其实相当于 hash % cap

```
我们来举个例子：
十进制：n = 8 ， hash = 11 ，hash % n = 3，
二进制：n - 1 = 7 = 111 , hash = 1011 , 111 & 1011 = 11 
一样的吧，原因就在于n - 1转化为2进制时所有的bit位都是1！
```

这里我们可以解释为什么需要加载因子loadFactor以及阈值threshold了，试想，如果我们没有阈值，只有在哈希表所有的位置都不为NULL时才进行扩容，我们不能保证HashCode可以的通过计算数组下标的算法匀称的分布在哈希表的每个下标上，这样带来的后果就是当哈希表满了需要扩容的时候每一个节点上的链表或者红黑树已经很庞大了！

加载因子0.75是在时间和空间上的一个权衡考虑，加载因子太大，不同的Key安置在哈希表同一个位置的概率就会增大，对应的链表会增长，get时间会增加；加载因子太小，则哈希表的利用率就比较小了，是对空间的浪费

当不同的key计算出的数组下标相同时，会产生所谓的`碰撞`


---

### 功能实现

#### put方法

```java
/**
 * Associates the specified value with the specified key in this map.
 * If the map previously contained a mapping for the key, the old
 * value is replaced.
 *
 * @param key key with which the specified value is to be associated
 * @param value value to be associated with the specified key
 * @return the previous value associated with <tt>key</tt>, or
 *         <tt>null</tt> if there was no mapping for <tt>key</tt>.
 *         (A <tt>null</tt> return can also indicate that the map
 *         previously associated <tt>null</tt> with <tt>key</tt>.)
 */
public V put(K key, V value) {
    return putVal(hash(key), key, value, false, true);
}
```
这里是直接调用了putVal()方法

```java
/**
* Implements Map.put and related methods
*
* @param hash hash for key
* @param key the key
* @param value the value to put
* @param onlyIfAbsent if true, don't change existing value
* @param evict if false, the table is in creation mode.
* @return previous value, or null if none
*/
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
              boolean evict) {
   Node<K,V>[] tab; Node<K,V> p; int n, i;
   // 初次进行put操作时，哈希表通过resize()进行初始化
   if ((tab = table) == null || (n = tab.length) == 0)
       n = (tab = resize()).length;
   // 如果通过(n - 1) & hash得到的数组下标处Node为NULL，则直接赋值
   if ((p = tab[i = (n - 1) & hash]) == null)
       tab[i] = newNode(hash, key, value, null);
   // 如果通过(n - 1) & hash得到的数组下标处Node不为NULL，则进行下述操作
   else {
       Node<K,V> e; K k;
       // 如果Hash值和Key值都相同(针对链表中首个Node)
       if (p.hash == hash &&
           ((k = p.key) == key || (key != null && key.equals(k))))
           e = p;
       // 如果该节点为红黑树
       else if (p instanceof TreeNode)
           e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
       // 如果该节点为链表
       else {
       	   // 遍历链表
           for (int binCount = 0; ; ++binCount) {
           	   // 如果链表中不包含Hash值和KEY值相同的节点
           	   // 如果已经到达链表尾部，则在链表尾部添加新的Node
               if ((e = p.next) == null) {
                   p.next = newNode(hash, key, value, null);
                   // 如果链表长度已经达到TREEIFY_THRESHOLD（默认值8），链表转换为红黑树
                   if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                       treeifyBin(tab, hash);
                   break;
               }
               // 如果链表中包含KEY值相同的节点
               if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    break;
                p = e;
            }
        }

        // 如果根据Hash值和KEY值和找到了相同的元素，则将该节点的Value替换为外部入参Value
        if (e != null) { // existing mapping for key
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            afterNodeAccess(e);
            return oldValue;
        }
    }
    // 结构性修改，用于fast-fail
    ++modCount;
    // 如果哈希表size超过了阈值，则进行扩容
    if (++size > threshold)
        resize();
    afterNodeInsertion(evict);
    return null;
}

```
先介绍下该函数的用处（虽然几乎所有人都知道~）

* 将 Key 和 Value 绑定在一起
* 如果HashMap中存在该Key，则用新的Value替换旧的Value
* 如果HashMap中存在该Key，则该函数返回旧的Value，否则，返回NULL

我们针对代码中的一些要点做下解释：

* 这里判断key值是否相同均采用先判断hash值是否相等再判断是否equals的，想想为什么？
* 1.8版本中新元素插入链表尾部的，和之前版本插入头部不同


#### resize方法

```java
/**
 * Initializes or doubles table size.  If null, allocates in
 * accord with initial capacity target held in field threshold.
 * Otherwise, because we are using power-of-two expansion, the
 * elements from each bin must either stay at same index, or move
 * with a power of two offset in the new table.
 *
 * @return the table
 */
final Node<K,V>[] resize() {
    Node<K,V>[] oldTab = table;
    int oldCap = (oldTab == null) ? 0 : oldTab.length;
    int oldThr = threshold;
    int newCap, newThr = 0;
    /** 下述为 HashMap基本属性以及哈希表初始化 **/
    if (oldCap > 0) {
    	// 如果哈希表的容量已经超过了最大值，只调整当前哈希表的阈值
    	// 不做扩容操作
        if (oldCap >= MAXIMUM_CAPACITY) {
            threshold = Integer.MAX_VALUE;
            return oldTab;
        }
        // 正常情况下，扩容一倍
        else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&
                 oldCap >= DEFAULT_INITIAL_CAPACITY)
            newThr = oldThr << 1; // double threshold
    }
    // 下述个根据不同的构造函数产生的容量以及阈值
    else if (oldThr > 0) // initial capacity was placed in threshold
        newCap = oldThr;
    else {               // zero initial threshold signifies using defaults
        newCap = DEFAULT_INITIAL_CAPACITY;
        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
    }
    if (newThr == 0) {
        float ft = (float)newCap * loadFactor;
        newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?
                  (int)ft : Integer.MAX_VALUE);
    }
    threshold = newThr;
    @SuppressWarnings({"rawtypes","unchecked"})
        Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
    table = newTab;
    /** 上述为 HashMap基本属性以及哈希表初始化 **/

    /** 下述为HashMap扩容机制 **/
    if (oldTab != null) {
        for (int j = 0; j < oldCap; ++j) {
            Node<K,V> e;
            if ((e = oldTab[j]) != null) {
            	// 将原始哈希表当前下标置空，节省空间
                oldTab[j] = null;
                // 下标j处只有一个元素
                if (e.next == null)
                    newTab[e.hash & (newCap - 1)] = e;
                // 红黑树类型
                else if (e instanceof TreeNode)
                    ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                // 链表类型
                else { // preserve order
                    Node<K,V> loHead = null, loTail = null;
                    Node<K,V> hiHead = null, hiTail = null;
                    Node<K,V> next;
                    /** 此处看后续详解① begin**/
                    do {
                        next = e.next;
                        if ((e.hash & oldCap) == 0) {
                            if (loTail == null)
                                loHead = e;
                            else
                                loTail.next = e;
                            loTail = e;
                        }
                        else {
                            if (hiTail == null)
                                hiHead = e;
                            else
                                hiTail.next = e;
                            hiTail = e;
                        }
                    } while ((e = next) != null);
                    /** 此处看后续详解① end**/
                    // 保持原始位置不变的Node
                    if (loTail != null) {
                        loTail.next = null;
                        newTab[j] = loHead;
                    }
                    // 偏移一个增量后的Node
                    if (hiTail != null) {
                        hiTail.next = null;
                        newTab[j + oldCap] = hiHead;
                    }
                }
            }
        }
    }
    /** 上述为HashMap扩容机制 **/
    return newTab;
}
```

先介绍下该函数的用处
* 初始化哈希表或者将哈希表扩容为两倍
* 扩容之后，之前的Node要么保持原有位置，要么偏移一个增量（扩展的容量）


我们针对代码中的一些难点做下解释：

* 哈希表分配空间是在resize中统一处理的！
* <font color='red'>扩容机制</font>

扩容后，带来的变化就是元素位置的变化和迁移，如何确定新哈希表中元素的下标呢？
对于只有一个元素的链表和红黑树这里就不做解释了，下面我们着重看下含有多个元素的链表的处理方式：

我们知道，数组下标是根据`(n-1) & hash`来确定的，哈希表扩容也就意味着capacity对应的二进制左移一位，那我们是不是可以用新的容量newCap-1的值转换为2进制的最高位和hash对应的位置做与操作，如果为0，表示该元素仍然待在原始位置，如果为1，则表示该元素要偏移增量个位置，下述我们举例说明：

```
初始容量oldCap ：十进制：8； 二进制：1000
扩容容量newCap ：十进制：16；二进制：10000
假设hash值     ：十进制：27；二进制：11011

那么初始的index为：( oldCap - 1 ) & hash
111 & 11011 = 11

扩容后的index位：( newCap - 1 ) & hash
1111 & 11011 = 1011

我们比对下新旧两种扩容的二进制算法，发现扩容后只是最高位多了一个1，hash值是不变的，
index要不要改变，全看hash值和最高位的与操作结果，如果hash值和最高位对应的bit位为0，
则index不变，如果bit位为1，则index要偏移一个扩容的容量，对应上述例子就是1000，即8

```
* 1.8版本和之前的版本在resize过程存在较大差异



#### get方法

```java
/**
 * Returns the value to which the specified key is mapped,
 * or {@code null} if this map contains no mapping for the key.
 *
 * <p>More formally, if this map contains a mapping from a key
 * {@code k} to a value {@code v} such that {@code (key==null ? k==null :
 * key.equals(k))}, then this method returns {@code v}; otherwise
 * it returns {@code null}.  (There can be at most one such mapping.)
 *
 * <p>A return value of {@code null} does not <i>necessarily</i>
 * indicate that the map contains no mapping for the key; it's also
 * possible that the map explicitly maps the key to {@code null}.
 * The {@link #containsKey containsKey} operation may be used to
 * distinguish these two cases.
 *
 * @see #put(Object, Object)
 */
public V get(Object key) {
    Node<K,V> e;
    return (e = getNode(hash(key), key)) == null ? null : e.value;
}
```
这里是直接调用了getNode方法

```java
/**
 * Implements Map.get and related methods
 *
 * @param hash hash for key
 * @param key the key
 * @return the node, or null if none
 */
final Node<K,V> getNode(int hash, Object key) {
    Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (first = tab[(n - 1) & hash]) != null) {
        // 先判断第一个Node是否就是我们需要的
        if (first.hash == hash && // always check first node
            ((k = first.key) == key || (key != null && key.equals(k))))
            return first;
        if ((e = first.next) != null) {
        	// 红黑树取Node
            if (first instanceof TreeNode)
                return ((TreeNode<K,V>)first).getTreeNode(hash, key);
            // 遍历链表取hash值和key相同的Node
            do {
                if (e.hash == hash &&
                    ((k = e.key) == key || (key != null && key.equals(k))))
                    return e;
            } while ((e = e.next) != null);
        }
    }
    return null;
}
```

先介绍下该函数的用处
* 根据key返回对应的Value值，如果不存在该key，则返回null
* 根据key得到的返回值null并不能说明不存在该key，有可能该key对应的Value就是null
* 可以根据containsKey判断hashmap中是否包含该key

这个函数比较简单，没啥好说的~


### 小结
* 1.8版本的HashMap相对之前版本的做了很大的改动（红黑树、resize等操作）
* HahMap的resize过程比较耗时，尤其在数据量较大的情况，如果可以预估Key-Value的数量，请初始化HashMap容量
* 各位在阅读代码时，尽量先阅读下方法的注释（有道翻译走起），这样有助于宏观上掌握
* 根据源码，我们可以看出来HashMap并不是线程安全的，这点会在下章介绍，敬请关注~



<br>
